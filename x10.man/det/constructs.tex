\subsection{Accumulators}

Each async (dynamically) has a set of registered \code{@Sync} accumulators
  and \code{@Async} accumulators.
  \begin{itemize}
  \item The registered \code{@Async} accumulators for an activity are the
    registered \code{@Sync} and \code{@Async} accumulators of its parent activity.

  \item The registered \code{@Sync} accumulators for an activity are the ones it has
    created. 
  \end{itemize}

 This permits computations to be determinate even though
 objects can be stored in heaps, since no async other than a child of
 the async that creates the accumulator can actually operate on
 them. One can still use the flexibility of the heap to arrange for
 complex data-dependent transmission pathways for the accumulator from
 point of creation to point of use. e.g.{} arrays of accumulators,
 hash-maps, etc.

The method 
\begin{lstlisting}
Runtime.isRegistered[T](x:Acc[T]):Int  
\end{lstlisting}

\noindent returns \code{0} if \code{x} is not registered with the
current activity, \code{1} if it is \code{@Sync} registered, and \code{2} if
it is \code{@Async} registered.

//  * Note: Runtime.isRegistered(Clock):Boolean should also be provided
//    for symmetry.

An invocation \code{e.m(e1,...,en)} of an \code{@Sync} method on an \code{Acc} is
  translated to: 
\begin{lstlisting}
{ 
  val x = e;
  if (Runtime.isRegistered(x) !=1) 
    throw new IllegalAccAccess(x);
  Runtime.sync();
  x.m(e1,...,en)
}      
\end{lstlisting}
The \code{@Sync} methods on an \code{Acc} are ones that return its
current value (\code{@Read}) and ones that reset it (\code{@Write}).

An invocation \code{e.m(e1,...,en)} of an \code{@Async} method on an 
\code{Acc} is translated to: 
\begin{lstlisting}
{ 
  val x = e;
  if (Runtime.isRegistered(x)==0) 
    throw new IllegalAccAccess(x);
  x.m(e1,...,en);
}    
\end{lstlisting}

The only \code{@Async} method on an \code{Acc} is the one that offers an
update to its value (\code{@Write}).

In many cases the compiler can statically evaluate whether
\code{Runtime.isRegistered(x) > 0} and/or whether a call to 
\code{Runtime.sync()}  will suspend. 

It may then appropriately simplify the above code.

e.g. in the code below
\begin{lstlisting}
val x:Acc[Int] = new Acc[Int](0, Int.+);
finish for (i in 0..100000) async
   x <- i;
Console.OUT.println("x is " + x());  
\end{lstlisting}
\noindent the compiler can infer that \code{x()} wont suspend, due to
the \code{finish}. Hence it may eliminate the run-time suspension
check. Further it can establish that \code{x} is \code{@Sync}
registered with the current activity, hence it can eliminate the
access check. 

Notes:
\begin{itemize}
\item 
   There are no restrictions to storing Accs in
   data-structures or reading them. 

\item   However, any attempt to use it will fail unless the Acc is
   registered with the current activity.

\item   The runtime checks in Runtime.sync() and Runtime.registered(..)
   ensure that the operations on an Acc are determinate.

\item
   Static analyses similar to the ones performed for clocks may be
   performed to ensure that exceptions are not thrown.
\end{itemize}

\begin{proposition}
\code{Acc}'s are determinate under arbitrary usage.   
\end{proposition}

\subsection{Example use of \code{Acc}}
\begin{example}[Histogram]
\begin{lstlisting}
 @det
 def histogram(N:Int, A:Rail[Int(0..N)]):Rail[Int](N+1) {
    val result = new Rail[Acc[Int]](N+1, (Int)=>new Acc[Int](0,Int.+));
    finish for (i in A.values()) async {
       result(i) <- 1;
    }
    return new Rail[Int](N+1, (i:Int)=> result(i));
 }
\end{lstlisting}
\end{example}

\begin{example}[Distributed word-count]
\begin{lstlisting}
 // A DistHashMap is used because the input is a DistStream

 @det 
 def wordCount(m:DistStream[Word]):DistHashMap[Word,Int](m.dist) {
   val a = new DistHashMap[Word, Acc[Int]](m.dist, 
          (w:Word)=> new Acc[Int](Int.Sum)));
   finish for (p in m.dist.places()) async at(p) {
      for (word in m(p).words())
          a(word)<- 1;
   }
   return  new DistHashMap[Word, Int](m.dist, (w:Word)=> a(w));
}
\end{lstlisting}
  
\end{example}


Accumulators can be used to implement collective operations such as
all-to-all reductions in a straightforward ``shared memory'' style.

Here we show the single-sided, blocking version.
\begin{example}
  \begin{lstlisting}
@det
def reduce[T](in:DistArray[T], red:Reducible[T]):T {
  val acc = new Acc[T](red);
  val temp = new GlobalRef[Acc[T]](acc);
  finish for (dest in in.dist.places()) async at(dest) {
    val local = new Acc[T](red);
    for (p in in.dist | here) {
      local <- in(p);
    }
    val x = local();
    async at(origin) temp() <- x;
  }
  return acc();
}    
\end{lstlisting}
\end{example}

An \code{allReduce} can be implemented by following the above
operation with a broadcast:
\begin{lstlisting}
  @det
  def allReduce[T](in:DistArray[T]{self.dist==Dist.UNIQUE}, 
    red:Reducible[T], out:DistArray[T](in.dist)):void {
    val x = reduce(in, red);
    finish for (dest in out.dist.places()) async at (dest) {
      for (p in out.dist |here)
        out(p)=x;
    }      
  }
\end{lstlisting}
One can write this code using a clock (to avoid two finish nests).

The collective style requires extending clock so the advance method
takes arbitrary args and performs collective operations on them,
mimicking the MPI API.


\subsection{Clocked types}

The central idea behind clocked data-structures is that read/write
conflicts are avoided using ``double buffering.'' Two versions of the
data-structure are kept, the {\em current} and the {\em next}
versions. Reads can be performed simultaneously by multiple activities
-- they are performed on the current version of the
data-structure. Writes are performed on the next version of the
data-structure. On detection of termination of the current phase --
when all involved activities are quiescent -- the current and the next
versions are switched.

\code{Clocked[T]} and \code{ClockedAcc[T]} are distinguished in that
unlike the former the latter permits accumulation operations.

Clocked objects are registered with activities, just like
accumulators.  This permits computations to be determinate even though
objects can be stored in heaps, since no async other than a child of
the async that creates the clocked object can actually operate on
them.

Each async (dynamically) has a set of registered clocked values. The
registered clocked values for an activity are the clocked values it
has created, and the ones registered to its parent activity.

\code{Clocked[T]}  has a constructor that takes two \code{T} arguments, these are
used to initialize the now and next fields. These arguments should be
``new'' (that is, no other data-structure should have a reference to
these arguments). 

For \code{x:Clocked[T]} the following operations available to any activity on which \code{x}
is registered:
\begin{itemize}
\item \code{x()} -- this returns the value of the current field. 
\item \code{x() = t} -- this sets the value of the next field. Note:
     write-write conflicts are possible since multiple activities may
     try to set the value at the same time.
\item\code{x.finalized()} -- this returns the value of the now field
  but modifies the internal state so that any subsequent attempt to
  use \code{x()=t} will result in a runtime exception.
\end{itemize}

\code{ClockedAcc[T]} has a constructor that takes two \code{T} values and a
\code{Reducer[T]} as argument. The two \code{T} values are used to initialize the
current and next fields. These arguments should be ``new'' (that is, no
other data-structure should have a reference to these arguments). The
reducer is used to perform accumulate operations.

Operations for \code{x:ClockedAcc[T]}:
\begin{itemize}
\item \code{x()} -- this returns the value of the now field. 
\item\code{x() <- t} -- this accumulates \code{t} into the next field. Note: No
     write-write conflicts are possible.
\item\code{x() = t} -- this resets the value of the next field to \code{t}. To avoid
     read/write and write/write conflics, this operation should be
     invoked only by the closure argument of
     \code{Clock.advanceAll(closure)}. (See below.)
\item \code{x.finalized()} -- this returns the value of the now field but
     modifies the internal state so that any attempt to use  \code{x()=t}
     or \code{x() <- t} will result in a runtime exception.
\end{itemize}

We add the following method on Clock:
\begin{lstlisting}
public static def advanceAll(x:()=>void) {...}
\end{lstlisting}

If all activities registered on the clock invoke \code{advanceAll(f)}
(for the same value \code{f}), then \code{f} is guaranteed to be
invoked by some activity A registered on the clock at a point in time
when all other activities have entered the \code{advanceAll(f)} call
and the current/next swap has been performed for all registered
clocked values.  At this point -- also called the {\em clock quiescent
point} -- it is guaranteed that none of the other activities are
performing a read or write operation on user-accessible memory.

(A possible implementation of \code{Clocked[T]} and
\code{ClockedAcc[T]} is that a system-synthesized closure (that
performs the current/next swap) is run at the clock quiescent point
before the user specified closure is run.)

\begin{example}
\begin{lstlisting}
@det
def stencil(a:Array[Double], eps:Double, P:Int) {
    val red = new Reducible[Double]() {
            public def zero()=0.0D;
            public operator this(x:Double, y:Double) = Math.max(x,y);
        };
    val err = new ClockedAcc[Double](Double.MAX_VALUE,
       Double.MAX_VALUE, red);
    val b = new Clocked[Array[Double](1)](
               new Array[Double](a.region, (p:Point(a.rank))=>0.0D);
               new Array[Double](a.region, (p:Point(a.rank))=>a(p)));

    clocked finish 
       for (myRegion in a.region.partition(P)) 
       clocked async {
       while (err() > eps) {
         for (k in myRegion) {

            val ck = (b()(k-1)+b()(k+1))/2;

            err() <- Double.abs(ck - b()(k));

            // @Write invocation on next. Det because each async
            // writes into its myRegion and each element of the array
            // of regions produced by a.region.partition(P) is disjoint
            // from the other.

            b()(k) = ck;
         }
         Clock.advanceAll();
       }
    }
    return b.finalized();
}
\end{lstlisting}
\end{example}


In the example above there is no need to reinitialize the value of
\code{err()} between phases since the value will monotonically
decrease. However for some other computations this may be
necessary. For example, suppose the error metric was the sum of all
errors. The the above code would change as follows. We would pass in a
different reduction operation red that sums rather than returns a max.
Further, we would replace the \code{Clock.advanceAll()} call with
\begin{lstlisting}
  Clock.advanceAll(()=>{err()=0.0D;});  
\end{lstlisting}

This resets the next value of err to be \code{0.0D} before the accumulations
start to happen.


